# Архитектурное решение по логированию


Необходимо организовать сбор `INFO` логов по каждой смене статуса заказа для отслеживания проблемы потерянных заказов

- [онлайн-магазин] - Заказ создан. customerId + orderId
- [онлайн-магазин] - Загружен файл. customerId + orderId + filepath
- [онлайн-магазин] - Заявка на заказ отправлена. customerId + orderId
- [MES] - Система посчитала стоимость заказа. orderId + calculation
- [CRM] - Заказ подтвержден. orderId + operatorId
- [MES] - Оператор взял заказ в работу. orderId + operatorId
- [MES] - Оператор выполнил заказ. orderId + operatorId
- [MES] - Оператор начал упаковывать заказ. orderId + operatorId
- [MES] - Заказ отправлен. orderId + deliveryInfo
- [CRM] - Заказ завершен. orderId

Также необходимо логировать все ошибки, которые могли произойти с уровнем `ERROR`

Для связки с `INFO` логами требуется ввести понятие requestId, для того, чтобы отслеживать как единый процесс.
Ошибки уровня ERROR необходимо ввести на транспортный уровень каждого сервиса, обеспечивающий запросы в базы, брокер, другие сревисы.

Также необходимо логировать состояния, которые потенциально могут угрожать стабильности системы. Например, ретраи с уровнем `WARNING`
Кроме того, в логи необходимо добавить информацию о запуске и остановке сервсов с уровнем `INFO`. Например, при неправильном развертывании, сервис может сбросить подключения и потерять данные.

## Мотивация
Логирование - наиболее важная часть наблюдаемости системы с точки зрения ошибок и бизнес-логики
С помощью логов можно изучать и понимать причины проблем, подробно отслеживать ход заказов и узнать какие ошибки происходили при выполнении того или иного запроса.
Логи позволят узнать о проблеме еще до обращения клиентов. Это особенно важно, учитывая, что часть пользователей может игнорировать проблему и уйти из продукта не оставив обратной связи.

### Технические и бизнес-метрики, на которые может повлиять внедрение логирования

- Количество потерянных заказов
- Number of HTTP 500
- Количество успешно выполненных заказов

Считаю, что логирование требует внедрения во всех системах до трейсинга.

## Предлагаемое решение

Техническое решение для облака - ELK, как наиболее популярный стек с развитым поиском.

### Шаги решения:

- Настроить стек ELK
- Настроить Logstash на прослушивание STDOUT проектов и запись логов в кибану
- Настроить права доступа на просмотр логов в кибане
- Каждый сервис настроить на запись логов уровня INFO, WARNING, ERROR в stdout

Впоследствии также внедрить логирование Frontend-сервисов с помощью Sentry для отслеживания клиентских ошибок

### Работа с чувствительными данными

**Со стороны сервисов:**

Определить поля и значения, которые могут быть чувствительны, например пароли, api-ключи. На стороне сервисов настроить клиент записи логов на скрытие значений перед отправкой в STDOUT

**Со стороны Kibana:**
Настроить права доступа. К логам должны иметь доступ разработчики, тимлид, специалисты поддержки и DevOps инженер.
Доступ по сети настроить аналогично трейсингу - только из внутренней сети или VPN.

Хранить логи не менее 2х месяцев в связи с длительным жизненным циклом заказа, далее удалять.
Создать отдельные индексы на каждый день.
Размер для хранения на данном этапе определить сложно, он должен поддерживать хранение не менее миллиона документов за два месяца для возможности записи всех шагов всех заказов.

## Мероприятия для превращения системы сбора логов в систему анализа логов

Алертинг необходим, можно настроить отправку ботом в мессенджер и на почту.
Алерты отправлять на ошибки при смене статуса заказов а так же при превышении квоты на логи, так можно отследить отказ системы или DDoS-атаку

## Дополнительное задание

| **Критерий**                              | **ELK**                                         | **Grafana Loki + Promtail**                          | **Datadog / Splunk**                         | **OpenSearch**                                    |
| ----------------------------------------- | ----------------------------------------------- | ---------------------------------------------------- | -------------------------------------------- | ------------------------------------------------- |
| **Лицензия**                              | Elasticsearch: SSPL (огранич. open-source)      | Apache 2.0 (open-source)                             | Проприетарные лицензии                       | Apache 2.0 (open-source)                          |
| **Стоимость лицензии**                    | Бесплатно (ограничено, платные опции у Elastic) | Бесплатно                                            | Платно (по объему данных и функционалу)      | Бесплатно                                         |
| **Потребление ресурсов**                  | Высокое (особенно Elasticsearch и Logstash)     | Низкое-среднее                                       | Высокое, но SaaS скрывает это                | Высокое (аналогично Elasticsearch)                |
| **Сложность внедрения**                   | Средне-высокая (особенно масштабирование)       | Низкая (легко разворачивается, особенно с Helm)      | Низкая (облачный сервис, SDK и агенты)       | Средняя (похож на ELK, но проще в лицензировании) |
| **Работа с высоконагруженными системами** | Хорошо, но требует тюнинга и ресурсов           | Хорошо при правильной настройке и ротации            | Отлично (поддерживается облаком)             | Хорошо, масштабируется                            |
| **Возможности для поиска**                | Очень гибкий поиск (Lucene DSL, Kibana)         | Ориентирован на "лог-потоки", поиск менее гибкий     | Отличный, с ML-поиском и фильтрами           | Полноценный поиск, как в ELK                      |
| **Возможность для алертинга**             | Да (через Kibana, Watcher, ElastAlert и др.)    | Да (в Grafana или через Prometheus Rule)             | Да, встроено (алерты, инциденты, интеграции) | Да (через OpenSearch Dashboards или сторонние)    |
| **Обработка клиентских логов**            | Через Filebeat, Logstash или агент              | Да, через Promtail (в браузер – через прокси/бэкенд) | Да (SDKs для JS, mobile и др.)               | Аналогично ELK                                    |
| **Обработка серверных логов**             | Да (де-факто стандарт)                          | Да                                                   | Да (универсальные агенты)                    | Да                                                |

Выбор ELK обоснован отличными возможностями поиска и де-факто стандартом индустрии. Среди минусов - высокое потребление ресурсов.
Как более дешевую альтернативу можно использовать Loki
